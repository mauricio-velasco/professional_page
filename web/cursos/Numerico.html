<html>
</head><title>An&aacutelisis Num&eacuterico:  Segundo Semestre 2022 </title></head>
<body bgcolor=white text=black link=#FF6600 alink=#0099CC 
vlink=#0099CC><font face="Trebuchet MS"><center>

<font size="10"> <b>An&aacutelisis Num&eacuterico</b><br> <p></p> 

<font size="5"> </center> 

<p> El an&aacutelisis num&eacuterico es la parte de las matem&aacuteticas que estudia algoritmos aproximados para la soluci&oacuten de problemas (t&iacutepicamente la soluci&oacuten de sistemas de ecuaciones lineales y no lineales pero tambi&eacuten es fundamental en problemas de optimizaci&oacuten). Tiene una larga e ilustre historia (con un desarrollo explosivo gracias a los computadores) y provee muchos conceptos centrales (como el n&uacutemero de condici&oacuten) que son transversales a todas las matem&aacuteticas. 
</p>

El texto principal del curso ser&aacuten las notas del instructor. Estas se basar&aacuten en los siguientes libros y notas de referencia (ver actividades clase a clase abajo):
<ul>
<li>[AC] Asher U., Chen G.: A first course in numerical methods, SIAM Computational Science and Engineering series (2011) </li> 
<li>[TB] Trefethen Ll., Bau D.: Numerical Linear Algebra, SIAM (1997)</li> 
<li>[O] Olver Peter: Numerical analysis Lecture notes, Chapter 14, Finite elements <a href="https://www-users.cse.umn.edu/~olver/num_/lnf.pdf"> [link]</a>
<li>[AAA] Ahmadi A.A.: Notas del m&eacutetodo de Newton, ORF363_Princeton (2015) <a href="http://www.princeton.edu/~aaa/Public/Teaching/ORF363_COS323/F15/ORF363_COS323_F15_Lec9.pdf"> [link]</a>
<li>[BNP] Bertsekas D.: Nonlinear Programming, Athena Scientific (1995)</li>

</ul>
La mayor parte de lo que aprender&aacuten en este curso ser&aacute el resultado de su propio trabajo en dos aspectos de igual de importancia: Reflexi&oacuten posterior a cada clase sobre los resultados discutidos en ella y trabajo en los ejercicios asignados clase a clase. El trabajo en grupo esta altamente recomendado.
<p>
Los criterios de evaluaci&oacuten del curso son:
<ul>
<p><li> Dos examenes parciales a realizarse en las fechas especificadas abajo (25%  c/u), un taller computacional de mitad de semestre (25%) y un trabajo final escrito (25%). El taller y el trabajo final deberan presentarse en grupos de dos o tres estudiantes, sobre un tema escogido por ustedes en el &aacuterea de An&aacutelisis num&eacuterico o sus aplicaciones. Las preguntas de los examenes parciales ser&aacuten variaciones menores de los ejercicios asignados en clase.</li></p>

<p><li> El trabajo final consiste de tres entregas:
<ul>
	<li> Entrega 1 - 10% (Semana 4): Documento que incluya: Integrantes del grupo (2 &oacute 3 personas por grupo), tema escogido, un p&aacuterrafo que explique por qu&eacute lo consideran un tema interesante y al menos 3 fuentes bibliogr&aacuteficas.</li>
	<li> Entrega 2 - 40% (Semana 10): C&oacutedigo en Julia que muestre los resultados del proyecto y una presentaci&oacuten oral breve (15mins) compartiendo en clase los resultados computacionales obtenidos.</li>
	<li>Entrega 3 - 50% (Semana 16): Consiste de tres partes
		<ul>
		<li>C&oacutedigo en Julia del proyecto</li>
		<li>Presentaci&oacuten oral (20 mins) de los resultados finales del proyecto.</a></li>
		<li>Documento que describa los resultados del proyecto. Deber&aacute hacerse en el estilo de los: what is....? de la revista "Notices of the AMS" <a href="http://www.ams.org/notices/200511/what-is.pdf"> [ver uno]</a> &oacute <a href="http://arminstraub.com/math/what-is-column"> [m&aacutes ejemplos] </a></li> 
		</ul>

</ul>


<p><li> El taller computacional consiste en implementar el m&eacutetodo de elementos finitos para la soluci&oacuten aproximada de ecuaciones diferenciales. Concretamente deben reproducir los resultados de los Ejemplos 14.3 (Figura 14.3) y Ejemplo 14.9 (figuras 14.11, 14.12 y 14.16) de la referencia [O] de arriba mediante sus propias implementaciones (de nuevo en grupos de 3). Debe entregarse en la &uacuteltima clase de la semana anterior a receso. </li>
</ul></p>


<p><li> La nota final se decidir&aacute calculando el promedio aritmetico de las cuatro notas de arriba (parciales, taller computacional y proyecto) y redonde&aacutendola al multiplo de 0.5 mas cercano. NO se recibiran trabajos tarde y NO se permitira la entrega de parciales en otras fechas salvo con incapacidad medica (por favor reserven desde hoy las fechas de parciales marcadas abajo). </li></p>
</ul>


<ul>
<li> Link para ver los EJERCICIOS (hacer click en Recompile y Download): <a href="https://www.overleaf.com/read/czsbfpytspkv"> [link] </a> </li>	
</ul>
		
<font size="5"> </center> 


<ul>
<p> SYLLABUS CLASE A CLASE: 
<table border="1">
<tr>
<td> Semana </td>
<td> Topic </td>
<td> Fecha </td>
<td> Tema </td>
</tr>



<tr>
<td> </td>
<td> Parcial 1 -- Clase del Viernes</td>
<td> Septiembre 23 </td>
<td> Parcial 1</td>
</tr>


<tr>
<td> </td>
<td> Parcial 2 -- Clase del Mi&eacutercoles</td>
<td> Noviembre 9 </td>
<td> Parcial 2</td>
</tr>





<!--

Semana 1,2: Factorizacion QR
Semana 3: Aplicaciones: Resolver sistemas lineales y problemas de minimos cuadrados
Ejercicios: 
Semanas 4,5: El método de elementos finitos
Semana 6: Ejercicios
Semana 7: Parcial 1
Semana 8: Entrega del taller computacional
Semana 8,9,10: Conditioning and stability
	-Normas matriciales
	-Floating point arithmetic
	-Def de estabilidad
	-Def de numero de condicion
	-Un algoritmo estable
	-Conditioning of least square problems
Semana 11,12: Computation of Eigenvalues, Schur normal form
Semana 13: Singular value decomposition
Semana 14,15: Ejercicios y Parcial
Semanas 16: Newton's method.





<tr>
<td> 1.1 </td>
<td> Matrices ortogonales, Normas matriciales [TB:3 ] </td>
<td> Enero 26</td>
<td> Preliminares</td>
</tr>


<tr>
<td> 2.1 </td>
<td> Singular Value Decomposition [TB,5] </td>
<td> </td>
<td> Preliminares</td>
</tr>

<tr>
<td> 2.2 </td>
<td> Aplicaciones de SVD (aproximacion de bajo rango y PCA) [TB:6 ,AG: Ex. 4.18]</td>
<td> </td>
<td> Preliminares</td>
</tr>


<tr>
<td> 3.1 </td>
<td> Descomposici&oacuten LU [TB: 20, AG: 5.2] y aplicaciones [AG:Ex. 5.3, 5.6]</td>
<td> </td>
<td> Sistemas Lineales: M&eacutetodos directos</td>
</tr>


<tr>
<td> 3.2 </td>
<td> Pivoteo y estabilidad [TB: 21,22]</td>
<td> </td>
<td> Sistemas Lineales: M&eacutetodos directos</td>
</tr>

<tr>
<td> 4.1 </td>
<td> Factorizaci&oacuten de Choleski [TB: 23, AG:5.5]</td>
<td> </td>
<td> Sistemas Lineales: M&eacutetodos directos</td>
</tr>

<tr>
<td> 4.2 </td>
<td> Sparse matrices [AG: 5.6,5.7] y <b>Entrega 1 Proyecto final</b>.</td>
<td> </td>
<td> Sistemas Lineales: M&eacutetodos directos</td>
</tr>

<tr>
<td> 5.1 </td>
<td> Numero de condici&oacuten [AG: 5.8, TB: 12]</b>.</td>
<td> </td>
<td> Sistemas Lineales: M&eacutetodos directos</td>
</tr>

<tr>
<td> 5.2 </td>
<td> Floating point arithmetic y estabilidad [TB: 14,15]</b>.</td>
<td> </td>
<td> Sistemas Lineales: M&eacutetodos directos</td>
</tr>

<tr>
<td> 5.3 </td>
<td> <b> Parcial 1</b>.</td>
<td> </td>
<td> Sistemas Lineales: M&eacutetodos directos</td>
</tr>

<tr>
<td> 6.1 </td>
<td> Factorizaci&oacuten QR [Motivación AG: 6.1, 6.2] [TB: 6,7]</b>.</td>
<td> </td>
<td> M&iacutenimos cuadrados lineales</td>
</tr>

<tr>
<td> 6.2 </td>
<td> Transformaciones de Householder y m&iacutenimos cuadrados [TB: 10,11]</b>.</td>
<td> </td>
<td> M&iacutenimos cuadrados lineales</td>
</tr>

<tr>
<td> 7.1 </td>
<td> Motivaci&oacuten: Soluci&oacuten de la Poisson equation [AG: Ex. 7.1]</b>.</td>
<td> </td>
<td> Sistemas lineales: M&eacutetodos iterativos</td>
</tr>

<tr>
<td> 7.2 </td>
<td> M&eacutetodos estacionarios [AG: 7.2,7.3]</b>.</td>
<td> </td>
<td> Sistemas lineales: M&eacutetodos iterativos</td>
</tr>


<tr>
<td> 8.1 </td>
<td> Gradiente conjugado [AG: 7.4]</b>.</td>
<td> </td>
<td> Sistemas lineales: M&eacutetodos iterativos</td>
</tr>

<tr>
<td> 8.2 </td>
<td> Precondicionadores [AG: 7.4]</b>.</td>
<td> </td>
<td> Sistemas lineales: M&eacutetodos iterativos</td>
</tr>


<tr>
<td> 9.1 </td>
<td> Motivaci&oacuten (The PageRank algorithm [AG:Ex.8.1] y Latent semantic analysis [AG:8.2])</b>.</td>
<td> </td>
<td> C&aacutelculo de valores propios y valores singulares</td>
</tr>

<tr>
<td> 9.2 </td>
<td> Overview of eigenvalue algorithms [TB: 25,26]</b>.</td>
<td> </td>
<td> C&aacutelculo de valores propios y valores singulares</td>
</tr>

<tr>
<td> 10.1 </td>
<td> Algoritmo QR [TB: 28,29]</b>.</td>
<td> </td>
<td> C&aacutelculo de valores propios y valores singulares</td>
</tr>

<tr>
<td> 10.2 </td>
<td> C&aacutelculo de SVD [TB: 31] y <b>Entrega 2 Proyecto final</b></b>.</td>
<td> </td>
<td> C&aacutelculo de valores propios y valores singulares</td>
</tr>

<tr>
<td> 10.3 </td>
<td> <b> Parcial 2</b>.</td>
<td> </td>
<td> </td>
</tr>


<tr>
<td> 11.1 </td>
<td> Motivación: Condiciones locales de optimalidad [BNP, Prop 1.1.2 y Prop.1.1.3]</b>.</td>
<td> </td>
<td> Optimizaci&oacuten global num&eacuterica</td>
</tr>

<tr>
<td> 11.2 </td>
<td> Metodos de descenso de gradiente  [BNP, 1.2]</b>.</td>
<td> </td>
<td> Optimizaci&oacuten global num&eacuterica</td>
</tr>


<tr>
<td> 12.1 </td>
<td> Convergencia cuadrática del método de Newton,p.1 [AAA]</b>.</td>
<td> </td>
<td> Optimizaci&oacuten global num&eacuterica</td>
</tr>
 

<tr>
<td> 12.2 </td>
<td> Convergencia cuadrática del método de Newton,p.2 [AAA]</b>.</td>
<td> </td>
<td> Optimizaci&oacuten global num&eacuterica</td>
</tr>

<tr>
<td> 13.1 </td>
<td> Convergencia cuadratica del metodo de Newton,p.3 [AAA]</b>.</td>
<td> </td>
<td> Optimizaci&oacuten global num&eacuterica</td>
</tr>

<tr>
<td> 13.2 </td>
<td> Minimos cuadrados no lineales [AAA] (Aplicaci&oacuten a redes neuronales)</b>.</td>
<td> </td>
<td> Optimizaci&oacuten global num&eacuterica</td>
</tr>

<tr>
<td> 14-16 </td>
<td> T&oacutepicos especiales y <b>Entrega 3 Proyecto final</b></b>.</td>
<td> </td>
<td> TBA</td>
</tr>

<tr>
<td> 16.3 </td>
<td> <b>Examen final</b></b>.</td>
<td> </td>
<td> </td>
</tr>


<font size="5"> </center> 

-->